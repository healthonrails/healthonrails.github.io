
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Annolid on Detectron2 Tutorial 3 : Evaluating the model &#8212; Annolid Documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Annolid on Detectron2 Tutorial 4 : Running inference" href="Annolid_on_Detectron2_Tutorial_4_Running_inference.html" />
    <link rel="prev" title="Annolid on Detectron2 Tutorial 2 : Train a Model" href="Annolid_on_Detectron2_Tutorial_2_Train_a_Model.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/cpl_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Annolid Documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../content/README.html">
   Annolid Documentation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../content/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/high_level_overview.html">
   High level overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/how_to_install.html">
   How to install
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/docker_container.html">
   Docker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/gui_or_cli.html">
   GUI or CLI ?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/extract_frames.html">
   Extract frames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/labelling_images.html">
   How to label images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/save_labels.html">
   Save Labels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/create_coco.html">
   Create your COCO format dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/tips_and_tricks.html">
   Tips and tricks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Annolid_on_Detectron2_Tutorial_1_Introduction_to_Detectron2.html">
   Annolid on Detectron2 Tutorial 1 : Introduction to Detectron2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Annolid_on_Detectron2_Tutorial_2_Train_a_Model.html">
   Annolid on Detectron2 Tutorial 2 : Train a Model
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Annolid on Detectron2 Tutorial 3 : Evaluating the model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Annolid_on_Detectron2_Tutorial_4_Running_inference.html">
   Annolid on Detectron2 Tutorial 4 : Running inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Annolid_on_Detectron2_Tutorial_full.html">
   Annolid on Detectron2 Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Annolid_post_processing_distances.html">
   Calculate distances for a pair of instances in the same frame or the same instance across frames
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Annolid Zoo
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../content/annolid_zoo.html">
   Annolid ModelZoo
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Community
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../content/contributing.html">
   New contributor guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/get_in_touch.html">
   Get in touch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/licence.html">
   Licence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/cite_annolid.html">
   Cite Annolid
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/work_based_on_annolid.html">
   Work based on annolid
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/tutorials/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/healthonrails/annolid/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/healthonrails/annolid//issues/new?title=Issue%20on%20page%20%2Ftutorials/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/healthonrails/annolid/master?urlpath=tree/book/tutorials/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#upload-a-labeled-dataset">
   Upload a labeled dataset.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference-evaluation-using-the-trained-model">
   Inference &amp; evaluation using the trained model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#todo-expand-on-how-to-interpret-ap">
     #TODO: expand on  how to interpret AP
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Annolid on Detectron2 Tutorial 3 : Evaluating the model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#upload-a-labeled-dataset">
   Upload a labeled dataset.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference-evaluation-using-the-trained-model">
   Inference &amp; evaluation using the trained model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#todo-expand-on-how-to-interpret-ap">
     #TODO: expand on  how to interpret AP
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="annolid-on-detectron2-tutorial-3-evaluating-the-model">
<h1>Annolid on Detectron2 Tutorial 3 : Evaluating the model<a class="headerlink" href="#annolid-on-detectron2-tutorial-3-evaluating-the-model" title="Permalink to this headline">¶</a></h1>
<p>This is modified from the official colab tutorial of detectron2. Here, we will</p>
<ul class="simple">
<li><p>Evaluate our previously trained model.</p></li>
</ul>
<p>You can make a copy of this tutorial by “File -&gt; Open in playground mode” and play with it yourself. <strong>DO NOT</strong> request access to this tutorial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Is running in colab or in jupyter-notebook</span>
<span class="k">try</span><span class="p">:</span>
  <span class="kn">import</span> <span class="nn">google.colab</span>
  <span class="n">IN_COLAB</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span><span class="p">:</span>
  <span class="n">IN_COLAB</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># install dependencies: </span>
<span class="o">!</span>pip install <span class="nv">pyyaml</span><span class="o">==</span><span class="m">5</span>.3
<span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">torchvision</span>
<span class="n">TORCH_VERSION</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">CUDA_VERSION</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;torch: &quot;</span><span class="p">,</span> <span class="n">TORCH_VERSION</span><span class="p">,</span> <span class="s2">&quot;; cuda: &quot;</span><span class="p">,</span> <span class="n">CUDA_VERSION</span><span class="p">)</span>
<span class="c1"># Install detectron2 that matches the above pytorch version</span>
<span class="c1"># See https://detectron2.readthedocs.io/tutorials/install.html for instructions</span>
<span class="o">!</span>pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/<span class="nv">$CUDA_VERSION</span>/torch<span class="nv">$TORCH_VERSION</span>/index.html
<span class="c1"># If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.</span>

<span class="c1"># exit(0)  # After installation, you may need to &quot;restart runtime&quot; in Colab. This line can also restart runtime</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyyaml==5.3 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (5.3)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Yellow">WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.</span>
<span class=" -Color -Color-Yellow">You should consider upgrading via the &#39;/Users/chenyang/miniconda3/envs/ceed/bin/python -m pip install --upgrade pip&#39; command.</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch:  1.9 ; cuda:  1.9.0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/1.9.0/torch1.9/index.html
Requirement already satisfied: detectron2 in /Users/chenyang/Desktop/Developer/cpl/annolid/annolid/detectron2 (0.5)
Requirement already satisfied: Pillow&gt;=7.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (8.3.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: matplotlib in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (3.1.3)
Requirement already satisfied: pycocotools&gt;=2.0.2 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (2.0.2)
Requirement already satisfied: termcolor&gt;=1.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (1.1.0)
Requirement already satisfied: yacs&gt;=0.1.6 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (0.1.8)
Requirement already satisfied: tabulate in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (0.8.9)
Requirement already satisfied: cloudpickle in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (1.3.0)
Requirement already satisfied: tqdm&gt;4.29.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (4.43.0)
Requirement already satisfied: tensorboard in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (2.3.0)
Requirement already satisfied: fvcore&lt;0.1.6,&gt;=0.1.5 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (0.1.5.post20210804)
Requirement already satisfied: iopath&lt;0.1.10,&gt;=0.1.7 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (0.1.9)
Requirement already satisfied: future in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (0.18.2)
Requirement already satisfied: pydot in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (1.4.2)
Requirement already satisfied: omegaconf&gt;=2.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (2.1.0)
Requirement already satisfied: hydra-core&gt;=1.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (1.1.0)
Requirement already satisfied: black==21.4b2 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from detectron2) (21.4b2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: click&gt;=7.1.2 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from black==21.4b2-&gt;detectron2) (7.1.2)
Requirement already satisfied: typed-ast&gt;=1.4.2 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from black==21.4b2-&gt;detectron2) (1.4.3)
Requirement already satisfied: appdirs in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from black==21.4b2-&gt;detectron2) (1.4.4)
Requirement already satisfied: regex&gt;=2020.1.8 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from black==21.4b2-&gt;detectron2) (2021.8.3)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from black==21.4b2-&gt;detectron2) (3.7.4.3)
Requirement already satisfied: mypy-extensions&gt;=0.4.3 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from black==21.4b2-&gt;detectron2) (0.4.3)
Requirement already satisfied: toml&gt;=0.10.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from black==21.4b2-&gt;detectron2) (0.10.1)
Requirement already satisfied: pathspec&lt;1,&gt;=0.8.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from black==21.4b2-&gt;detectron2) (0.9.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyyaml&gt;=5.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from fvcore&lt;0.1.6,&gt;=0.1.5-&gt;detectron2) (5.3)
Requirement already satisfied: numpy in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from fvcore&lt;0.1.6,&gt;=0.1.5-&gt;detectron2) (1.18.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: antlr4-python3-runtime==4.8 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from hydra-core&gt;=1.1-&gt;detectron2) (4.8)
Requirement already satisfied: importlib-resources in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from hydra-core&gt;=1.1-&gt;detectron2) (5.2.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: portalocker in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from iopath&lt;0.1.10,&gt;=0.1.7-&gt;detectron2) (2.3.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: cython&gt;=0.27.3 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from pycocotools&gt;=2.0.2-&gt;detectron2) (0.29.16)
Requirement already satisfied: setuptools&gt;=18.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from pycocotools&gt;=2.0.2-&gt;detectron2) (44.0.0.post20200106)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: kiwisolver&gt;=1.0.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from matplotlib-&gt;detectron2) (1.1.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from matplotlib-&gt;detectron2) (2.8.1)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from matplotlib-&gt;detectron2) (2.4.6)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: cycler&gt;=0.10 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from matplotlib-&gt;detectron2) (0.10.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: absl-py&gt;=0.4 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (0.9.0)
Requirement already satisfied: grpcio&gt;=1.24.3 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (1.38.1)
Requirement already satisfied: six&gt;=1.10.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (1.14.0)
Requirement already satisfied: wheel&gt;=0.26 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (0.34.2)
Requirement already satisfied: markdown&gt;=2.6.8 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (3.1.1)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (2.26.0)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (0.4.1)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (0.16.0)
Requirement already satisfied: protobuf&gt;=3.6.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (3.17.3)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (1.7.0)
Requirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from tensorboard-&gt;detectron2) (1.32.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (4.0.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (0.2.8)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (4.0)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;detectron2) (1.3.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (2.9)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (1.25.8)
Requirement already satisfied: certifi&gt;=2017.4.17 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (2020.6.20)
Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (2.0.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: zipp&gt;=3.1.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from importlib-resources-&gt;hydra-core&gt;=1.1-&gt;detectron2) (3.5.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (0.4.8)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: oauthlib&gt;=3.0.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;detectron2) (3.1.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Yellow">WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.</span>
<span class=" -Color -Color-Yellow">You should consider upgrading via the &#39;/Users/chenyang/miniconda3/envs/ceed/bin/python -m pip install --upgrade pip&#39; command.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import some common libraries</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
  <span class="kn">from</span> <span class="nn">google.colab.patches</span> <span class="kn">import</span> <span class="n">cv2_imshow</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setup detectron2 logger</span>
<span class="kn">import</span> <span class="nn">detectron2</span>
<span class="kn">from</span> <span class="nn">detectron2.utils.logger</span> <span class="kn">import</span> <span class="n">setup_logger</span>
<span class="n">setup_logger</span><span class="p">()</span>

<span class="c1"># import some common detectron2 utilities</span>
<span class="kn">from</span> <span class="nn">detectron2</span> <span class="kn">import</span> <span class="n">model_zoo</span>
<span class="kn">from</span> <span class="nn">detectron2.engine</span> <span class="kn">import</span> <span class="n">DefaultPredictor</span>
<span class="kn">from</span> <span class="nn">detectron2.config</span> <span class="kn">import</span> <span class="n">get_cfg</span>
<span class="kn">from</span> <span class="nn">detectron2.utils.visualizer</span> <span class="kn">import</span> <span class="n">Visualizer</span>
<span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">MetadataCatalog</span><span class="p">,</span> <span class="n">DatasetCatalog</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># is there a gpu</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">GPU</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;gpu available&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">GPU</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;no gpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>no gpu
</pre></div>
</div>
</div>
</div>
<div class="section" id="upload-a-labeled-dataset">
<h2>Upload a labeled dataset.<a class="headerlink" href="#upload-a-labeled-dataset" title="Permalink to this headline">¶</a></h2>
<p>The following code is expecting the dataset in the COCO format to be in a <em><strong>.zip</strong></em> file. For example: <code class="docutils literal notranslate"><span class="pre">sample_dataset.zip</span></code> <br />
Note: please make sure there is no white space in your file path if you encounter file not found issues.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install gdown 
<span class="o">!</span>gdown --id 1fUXCLnoJ5SwXg54mj0NBKGzidsV8ALVR
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: gdown in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (4.2.1)
Requirement already satisfied: requests[socks] in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from gdown) (2.26.0)
Requirement already satisfied: six in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from gdown) (1.14.0)
Requirement already satisfied: filelock in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from gdown) (3.0.12)
Requirement already satisfied: tqdm in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from gdown) (4.43.0)
Requirement already satisfied: beautifulsoup4 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from gdown) (4.10.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: soupsieve&gt;1.2 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from beautifulsoup4-&gt;gdown) (2.3.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests[socks]-&gt;gdown) (1.25.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests[socks]-&gt;gdown) (2.0.1)
Requirement already satisfied: certifi&gt;=2017.4.17 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests[socks]-&gt;gdown) (2020.6.20)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests[socks]-&gt;gdown) (2.9)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /Users/chenyang/miniconda3/envs/ceed/lib/python3.7/site-packages (from requests[socks]-&gt;gdown) (1.7.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Yellow">WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.</span>
<span class=" -Color -Color-Yellow">You should consider upgrading via the &#39;/Users/chenyang/miniconda3/envs/ceed/bin/python -m pip install --upgrade pip&#39; command.</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading...
From: https://drive.google.com/uc?id=1fUXCLnoJ5SwXg54mj0NBKGzidsV8ALVR
To: /Users/chenyang/Desktop/Developer/cpl/annolid/book/tutorials/novelctrlk6_8_coco_dataset.zip
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|                                               | 0.00/10.3M [00:00&lt;?, ?B/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  5%|█▉                                     | 524k/10.3M [00:00&lt;00:03, 3.03MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10%|███▊                                  | 1.05M/10.3M [00:00&lt;00:02, 3.44MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20%|███████▋                              | 2.10M/10.3M [00:00&lt;00:02, 3.91MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 31%|███████████▌                          | 3.15M/10.3M [00:00&lt;00:01, 4.24MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36%|█████████████▌                        | 3.67M/10.3M [00:00&lt;00:01, 4.40MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 46%|█████████████████▍                    | 4.72M/10.3M [00:00&lt;00:01, 4.81MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 56%|█████████████████████▎                | 5.77M/10.3M [00:01&lt;00:00, 4.65MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 61%|███████████████████████▏              | 6.29M/10.3M [00:01&lt;00:00, 4.34MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 66%|█████████████████████████             | 6.82M/10.3M [00:01&lt;00:00, 4.43MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 71%|███████████████████████████           | 7.34M/10.3M [00:01&lt;00:00, 4.05MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76%|████████████████████████████▉         | 7.86M/10.3M [00:01&lt;00:00, 3.66MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 81%|██████████████████████████████▉       | 8.39M/10.3M [00:01&lt;00:00, 3.45MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86%|████████████████████████████████▊     | 8.91M/10.3M [00:02&lt;00:00, 3.58MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97%|████████████████████████████████████▋ | 9.96M/10.3M [00:02&lt;00:00, 3.96MB/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████████████████████████████████| 10.3M/10.3M [00:02&lt;00:00, 4.44MB/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="s1">&#39;/content/novelctrlk6_8_coco_dataset.zip&#39;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="s1">&#39;novelctrlk6_8_coco_dataset.zip&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="o">!</span>unzip <span class="nv">$dataset</span> -d /content/
<span class="k">else</span><span class="p">:</span>
    <span class="c1">#TODO generalize this</span>
    <span class="o">!</span>unzip -o <span class="nv">$dataset</span> -d .
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Archive:  novelctrlk6_8_coco_dataset.zip
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001416_41.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004233_81.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004515_22.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000636_6.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006297_11.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006818_79.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006056_25.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006094_12.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004340_96.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000557_50.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000979_94.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005018_19.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001257_80.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004335_26.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004804_39.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006396_43.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006993_65.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000865_92.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003114_35.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001918_2.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004935_56.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006959_78.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005216_14.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003092_22.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001528_44.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003208_12.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004966_35.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004517_47.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004769_82.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004767_87.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000378_62.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006563_31.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001476_48.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004555_67.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003070_62.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005007_38.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003342_41.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002267_91.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002248_99.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000702_46.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003237_15.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002412_96.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001322_73.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002328_97.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004312_85.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004443_46.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003783_81.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000779_3.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002654_1.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004685_90.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004098_59.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006538_99.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006832_71.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00007024_26.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005772_51.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006330_76.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000871_10.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003034_64.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004539_89.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005788_49.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/annotations.json  
  inflating: ./novelctrlk6_8_coco_dataset/.DS_Store  
  inflating: ./__MACOSX/novelctrlk6_8_coco_dataset/._.DS_Store  
  inflating: ./novelctrlk6_8_coco_dataset/data.yaml  
  inflating: ./novelctrlk6_8_coco_dataset/train/.DS_Store  
  inflating: ./__MACOSX/novelctrlk6_8_coco_dataset/train/._.DS_Store  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001466_29.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006804_57.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00007044_50.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006232_55.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000759_28.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003680_32.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004441_88.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005090_94.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002476_27.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000965_42.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001652_55.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002000_18.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002333_0.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005752_39.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006670_0.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005763_18.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004469_75.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005566_43.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004336_74.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006574_88.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001922_1.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001795_5.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005755_34.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003576_54.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002647_78.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004295_47.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003667_56.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006131_85.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000311_77.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000879_40.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002991_7.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000757_5.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004628_68.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004348_33.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003269_66.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003224_49.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002628_21.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001838_25.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002825_40.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002247_29.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003100_30.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001922_57.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001320_92.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006299_63.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000952_60.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000842_70.jpg  
  inflating: ./__MACOSX/novelctrlk6_8_coco_dataset/train/JPEGImages/._00000842_70.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002295_32.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004117_59.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003976_44.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004032_20.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006212_69.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003134_31.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006169_98.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006830_36.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004570_24.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000735_23.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003905_42.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003012_37.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005456_95.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002456_9.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002433_90.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006715_97.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005597_15.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006319_53.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005025_83.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000530_64.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002362_63.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002311_72.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005068_37.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006353_11.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005056_91.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000970_34.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002577_24.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006601_16.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000652_65.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002639_95.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005953_8.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006000_27.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005700_89.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004672_51.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004062_19.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005246_28.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005154_53.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005584_93.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003834_80.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004711_6.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006038_20.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006373_2.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006470_84.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003956_16.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002625_79.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006270_45.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006521_86.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001999_45.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004081_4.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000776_14.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002546_58.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001181_61.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002226_87.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001632_33.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006218_71.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005400_9.jpg  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001299_86.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002067_75.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006844_69.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001892_72.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001153_93.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001389_82.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001439_52.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006367_98.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004018_67.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004535_48.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006361_13.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003167_10.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006832_66.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004956_38.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001980_61.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003364_13.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/annotations.json  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DATASET_NAME</span> <span class="o">=</span> <span class="n">DATASET_DIR</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;{dataset.replace(&#39;.zip&#39;,&#39;&#39;)}&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.data.datasets</span> <span class="kn">import</span> <span class="n">register_coco_instances</span>
<span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">get_detection_dataset_dicts</span>
<span class="kn">from</span> <span class="nn">detectron2.data.datasets</span> <span class="kn">import</span>  <span class="n">builtin_meta</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">register_coco_instances</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_train&quot;</span><span class="p">,</span> <span class="p">{},</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_DIR}</span><span class="s2">/train/annotations.json&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_DIR}</span><span class="s2">/train/&quot;</span><span class="p">)</span>
<span class="n">register_coco_instances</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_valid&quot;</span><span class="p">,</span> <span class="p">{},</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_DIR}</span><span class="s2">/valid/annotations.json&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_DIR}</span><span class="s2">/valid/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_dataset_metadata</span> <span class="o">=</span> <span class="n">MetadataCatalog</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_train&quot;</span><span class="p">)</span>
<span class="n">_dataset_metadata</span><span class="o">.</span><span class="n">thing_colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">cc</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">cc</span> <span class="ow">in</span> <span class="n">builtin_meta</span><span class="o">.</span><span class="n">COCO_CATEGORIES</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_dicts</span> <span class="o">=</span> <span class="n">get_detection_dataset_dicts</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_train&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:48 d2.data.datasets.coco]: </span>Loaded 118 images in COCO format from novelctrlk6_8_coco_dataset/train/annotations.json
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:48 d2.data.build]: </span>Removed 0 images with no usable annotations. 118 images left.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:48 d2.data.build]: </span>Distribution of instances among all 7 categories:
<span class=" -Color -Color-Cyan">|   category   | #instances   |  category  | #instances   |  category  | #instances   |</span>
<span class=" -Color -Color-Cyan">|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|</span>
<span class=" -Color -Color-Cyan">| _background_ | 0            |    nose    | 118          |  left_ear  | 118          |</span>
<span class=" -Color -Color-Cyan">|  right_ear   | 117          | tail_base  | 119          |   mouse    | 118          |</span>
<span class=" -Color -Color-Cyan">|   centroid   | 1            |            |              |            |              |</span>
<span class=" -Color -Color-Cyan">|    total     | 591          |            |              |            |              |</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">_dataset_metadata</span><span class="o">.</span><span class="n">thing_classes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{NUM_CLASSES}</span><span class="s2"> Number of classes in the dataset&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>7 Number of classes in the dataset
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="inference-evaluation-using-the-trained-model">
<h2>Inference &amp; evaluation using the trained model<a class="headerlink" href="#inference-evaluation-using-the-trained-model" title="Permalink to this headline">¶</a></h2>
<p>Now, let’s run inference with the trained model on the validation dataset. First, let’s create a predictor using the model we just trained:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">GPU</span><span class="p">:</span>
    <span class="o">!</span>nvidia-smi
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.engine</span> <span class="kn">import</span> <span class="n">DefaultTrainer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">get_cfg</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">GPU</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">DEVICE</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span><span class="o">.</span><span class="n">merge_from_file</span><span class="p">(</span><span class="n">model_zoo</span><span class="o">.</span><span class="n">get_config_file</span><span class="p">(</span><span class="s2">&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;</span><span class="p">))</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATASETS</span><span class="o">.</span><span class="n">TRAIN</span> <span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_train&quot;</span><span class="p">,)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATASETS</span><span class="o">.</span><span class="n">TEST</span> <span class="o">=</span> <span class="p">()</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATALOADER</span><span class="o">.</span><span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1">#@param</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATALOADER</span><span class="o">.</span><span class="n">SAMPLER_TRAIN</span> <span class="o">=</span> <span class="s2">&quot;RepeatFactorTrainingSampler&quot;</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATALOADER</span><span class="o">.</span><span class="n">REPEAT_THRESHOLD</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS</span> <span class="o">=</span> <span class="n">model_zoo</span><span class="o">.</span><span class="n">get_checkpoint_url</span><span class="p">(</span><span class="s2">&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;</span><span class="p">)</span>  <span class="c1"># Let training initialize from model zoo</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">IMS_PER_BATCH</span> <span class="o">=</span>  <span class="mi">4</span> <span class="c1">#@param</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">BASE_LR</span> <span class="o">=</span> <span class="mf">0.0025</span> <span class="c1">#@param # pick a good LR</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">MAX_ITER</span> <span class="o">=</span> <span class="mi">3000</span> <span class="c1">#@param    # 300 iterations seems good enough for 100 frames dataset; you will need to train longer for a practical dataset</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">CHECKPOINT_PERIOD</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1">#@param </span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">BATCH_SIZE_PER_IMAGE</span> <span class="o">=</span> <span class="mi">32</span> <span class="c1">#@param   # faster, and good enough for this toy dataset (default: 512)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="n">NUM_CLASSES</span>  <span class="c1">#  (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">DefaultTrainer</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> 
<span class="n">trainer</span><span class="o">.</span><span class="n">resume_or_load</span><span class="p">(</span><span class="n">resume</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:50 d2.engine.defaults]: </span>Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=8, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 7, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:51 d2.data.datasets.coco]: </span>Loaded 118 images in COCO format from novelctrlk6_8_coco_dataset/train/annotations.json
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:51 d2.data.build]: </span>Removed 0 images with no usable annotations. 118 images left.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:51 d2.data.dataset_mapper]: </span>[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style=&#39;choice&#39;), RandomFlip()]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:51 d2.data.build]: </span>Using training sampler RepeatFactorTrainingSampler
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:51 d2.data.common]: </span>Serializing 118 elements to byte tensors and concatenating them all ...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[05/03 10:13:51 d2.data.common]: </span>Serialized dataset takes 0.31 MiB
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">WARNING</span> <span class=" -Color -Color-Green">[05/03 10:13:51 d2.solver.build]: </span>SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skip loading parameter &#39;roi_heads.box_predictor.cls_score.weight&#39; to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skip loading parameter &#39;roi_heads.box_predictor.cls_score.bias&#39; to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skip loading parameter &#39;roi_heads.box_predictor.bbox_pred.weight&#39; to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skip loading parameter &#39;roi_heads.box_predictor.bbox_pred.bias&#39; to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skip loading parameter &#39;roi_heads.mask_head.predictor.weight&#39; to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (7, 256, 1, 1) in the model! You might want to double check if this is expected.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skip loading parameter &#39;roi_heads.mask_head.predictor.bias&#39; to the model due to incompatible shapes: (80,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Some model parameters or buffers are not found in the checkpoint:
<span class=" -Color -Color-Blue">roi_heads.box_predictor.bbox_pred.{bias, weight}</span>
<span class=" -Color -Color-Blue">roi_heads.box_predictor.cls_score.{bias, weight}</span>
<span class=" -Color -Color-Blue">roi_heads.mask_head.predictor.{bias, weight}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inference should use the config with parameters that are used in training</span>
<span class="c1"># cfg now already contains everything we&#39;ve set previously. </span>
<span class="c1"># We simply update the weights with the newly trained ones to perform inference:</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="s2">&quot;model_final.pth&quot;</span><span class="p">)</span>  <span class="c1"># path to the model we just trained</span>
<span class="c1"># set a custom testing threshold</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">SCORE_THRESH_TEST</span> <span class="o">=</span> <span class="mf">0.15</span>   <span class="c1">#@param {type: &quot;slider&quot;, min:0.0, max:1.0, step: 0.01}</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">DefaultPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AssertionError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">20</span><span class="o">-</span><span class="mi">8</span><span class="n">cfc9fd45316</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># set a custom testing threshold</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">SCORE_THRESH_TEST</span> <span class="o">=</span> <span class="mf">0.15</span>   <span class="c1">#@param {type: &quot;slider&quot;, min:0.0, max:1.0, step: 0.01}</span>
<span class="ne">----&gt; </span><span class="mi">7</span> <span class="n">predictor</span> <span class="o">=</span> <span class="n">DefaultPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>

<span class="nn">~/Desktop/Developer/cpl/annolid/annolid/detectron2/detectron2/engine/defaults.py</span> in <span class="ni">__init__</span><span class="nt">(self, cfg)</span>
<span class="g g-Whitespace">    </span><span class="mi">291</span> 
<span class="g g-Whitespace">    </span><span class="mi">292</span>         <span class="n">checkpointer</span> <span class="o">=</span> <span class="n">DetectionCheckpointer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">293</span>         <span class="n">checkpointer</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">294</span> 
<span class="g g-Whitespace">    </span><span class="mi">295</span>         <span class="bp">self</span><span class="o">.</span><span class="n">aug</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">ResizeShortestEdge</span><span class="p">(</span>

<span class="nn">~/Desktop/Developer/cpl/annolid/annolid/detectron2/detectron2/checkpoint/detection_checkpoint.py</span> in <span class="ni">load</span><span class="nt">(self, path, *args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span>             <span class="k">if</span> <span class="ow">not</span> <span class="n">has_file</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">52</span>                 <span class="n">path</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># don&#39;t load if not readable</span>
<span class="ne">---&gt; </span><span class="mi">53</span>         <span class="n">ret</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span> 
<span class="g g-Whitespace">     </span><span class="mi">55</span>         <span class="k">if</span> <span class="n">need_sync</span><span class="p">:</span>

<span class="nn">~/miniconda3/envs/ceed/lib/python3.7/site-packages/fvcore/common/checkpoint.py</span> in <span class="ni">load</span><span class="nt">(self, path, checkpointables)</span>
<span class="g g-Whitespace">    </span><span class="mi">139</span>         <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>             <span class="n">path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">path_manager</span><span class="o">.</span><span class="n">get_local_path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">141</span>             <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> <span class="s2">&quot;Checkpoint </span><span class="si">{}</span><span class="s2"> not found!&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">142</span> 
<span class="g g-Whitespace">    </span><span class="mi">143</span>         <span class="n">checkpoint</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_file</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="ne">AssertionError</span>: Checkpoint ./output/model_final.pth not found!
</pre></div>
</div>
</div>
</div>
<p>Then, we randomly select several samples to visualize the prediction results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.utils.visualizer</span> <span class="kn">import</span> <span class="n">ColorMode</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_dicts</span> <span class="o">=</span> <span class="n">get_detection_dataset_dicts</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_valid&quot;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">dataset_dicts</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>    
    <span class="n">im</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;file_name&quot;</span><span class="p">])</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>  <span class="c1"># format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">im</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                   <span class="n">metadata</span><span class="o">=</span><span class="n">_dataset_metadata</span><span class="p">,</span> 
                   <span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                   <span class="n">instance_mode</span><span class="o">=</span><span class="n">ColorMode</span><span class="o">.</span><span class="n">SEGMENTATION</span>   <span class="c1"># remove the colors of unsegmented pixels. This option is only available for segmentation models</span>
    <span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">draw_instance_predictions</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
        <span class="n">cv2_imshow</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">get_image</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">get_image</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[01/24 14:31:55 d2.data.datasets.coco]: </span>Loaded 60 images in COCO format from novelctrlk6_8_coco_dataset/valid/annotations.json
<span class=" -Color -Color-Green">[01/24 14:31:55 d2.data.build]: </span>Removed 0 images with no usable annotations. 60 images left.
<span class=" -Color -Color-Green">[01/24 14:31:55 d2.data.build]: </span>Distribution of instances among all 7 categories:
<span class=" -Color -Color-Cyan">|   category   | #instances   |  category  | #instances   |  category  | #instances   |</span>
<span class=" -Color -Color-Cyan">|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|</span>
<span class=" -Color -Color-Cyan">| _background_ | 0            |    nose    | 60           |  left_ear  | 60           |</span>
<span class=" -Color -Color-Cyan">|  right_ear   | 60           | tail_base  | 60           |   mouse    | 60           |</span>
<span class=" -Color -Color-Cyan">|   centroid   | 0            |            |              |            |              |</span>
<span class=" -Color -Color-Cyan">|    total     | 300          |            |              |            |              |</span>
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jeremy/anaconda3/envs/annolid-env/lib/python3.7/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the &#39;trunc&#39; function NOT &#39;floor&#39;). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode=&#39;trunc&#39;), or for actual floor division, use torch.div(a, b, rounding_mode=&#39;floor&#39;).
  max_size = (max_size + (stride - 1)) // stride * stride
/home/jeremy/anaconda3/envs/annolid-env/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
</pre></div>
</div>
<img alt="../_images/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model_25_2.png" src="../_images/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model_25_2.png" />
<img alt="../_images/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model_25_3.png" src="../_images/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model_25_3.png" />
<img alt="../_images/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model_25_4.png" src="../_images/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model_25_4.png" />
<img alt="../_images/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model_25_5.png" src="../_images/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model_25_5.png" />
</div>
</div>
<p>A more robust way to evaluate the model is to use a metric called Average Precision (AP) already implemented in the detectron2 package. If you want more precision on what the AP is, you can take a look <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score">here</a> and <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;oldid=793358396#Average_precision">here</a>.</p>
<div class="section" id="todo-expand-on-how-to-interpret-ap">
<h3>#TODO: expand on  how to interpret AP<a class="headerlink" href="#todo-expand-on-how-to-interpret-ap" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.evaluation</span> <span class="kn">import</span> <span class="n">COCOEvaluator</span><span class="p">,</span> <span class="n">inference_on_dataset</span>
<span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">build_detection_test_loader</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">COCOEvaluator</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_valid&quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;/content/eval_output/&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">COCOEvaluator</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_valid&quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;eval_output/&quot;</span><span class="p">)</span>

<span class="n">val_loader</span> <span class="o">=</span> <span class="n">build_detection_test_loader</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{DATASET_NAME}</span><span class="s2">_valid&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inference_on_dataset</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">evaluator</span><span class="p">))</span>
<span class="c1"># another equivalent way to evaluate the model is to use `trainer.test`</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">WARNING</span> <span class=" -Color -Color-Green">[01/24 14:31:56 d2.evaluation.coco_evaluation]: </span>COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.data.datasets.coco]: </span>Loaded 60 images in COCO format from novelctrlk6_8_coco_dataset/valid/annotations.json
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.data.dataset_mapper]: </span>[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style=&#39;choice&#39;)]
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.data.common]: </span>Serializing 60 elements to byte tensors and concatenating them all ...
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.data.common]: </span>Serialized dataset takes 0.15 MiB
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.evaluation.evaluator]: </span>Start inference on 60 batches
<span class=" -Color -Color-Green">[01/24 14:31:57 d2.evaluation.evaluator]: </span>Inference done 11/60. Dataloading: 0.0008 s/iter. Inference: 0.0523 s/iter. Eval: 0.0180 s/iter. Total: 0.0712 s/iter. ETA=0:00:03
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.evaluator]: </span>Total inference time: 0:00:03.823960 (0.069527 s / iter per device, on 1 devices)
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.evaluator]: </span>Total inference pure compute time: 0:00:02 (0.051859 s / iter per device, on 1 devices)
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Preparing results for COCO format ...
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Saving results to eval_output/coco_instances_results.json
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>Evaluate annotation type *bbox*
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>COCOeval_opt.evaluate() finished in 0.02 seconds.
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>Accumulating evaluation results...
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.823
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.796
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.464
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.797
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |
|:------:|:------:|:------:|:------:|:------:|:-----:|
| 42.881 | 82.250 | 40.677 | 34.808 | 79.604 |  nan  |
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Some metrics cannot be computed and is shown as NaN.
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Per-category bbox AP: 
| category     | AP     | category   | AP     | category   | AP     |
|:-------------|:-------|:-----------|:-------|:-----------|:-------|
| _background_ | nan    | nose       | 37.467 | left_ear   | 34.991 |
| right_ear    | 26.474 | tail_base  | 40.300 | mouse      | 75.175 |
| centroid     | nan    |            |        |            |        |
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>Evaluate annotation type *segm*
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>COCOeval_opt.evaluate() finished in 0.02 seconds.
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>Accumulating evaluation results...
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.138
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.207
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.190
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.689
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.712
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |
|:------:|:------:|:------:|:-----:|:------:|:-----:|
| 13.838 | 20.664 | 18.990 | 0.083 | 68.859 |  nan  |
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Some metrics cannot be computed and is shown as NaN.
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Per-category segm AP: 
| category     | AP    | category   | AP    | category   | AP     |
|:-------------|:------|:-----------|:------|:-----------|:-------|
| _background_ | nan   | nose       | 0.000 | left_ear   | 0.000  |
| right_ear    | 0.025 | tail_base  | 0.307 | mouse      | 68.859 |
| centroid     | nan   |            |       |            |        |
OrderedDict([(&#39;bbox&#39;, {&#39;AP&#39;: 42.881449697137505, &#39;AP50&#39;: 82.2501044835862, &#39;AP75&#39;: 40.67677036400211, &#39;APs&#39;: 34.80797160883607, &#39;APm&#39;: 79.60396039603961, &#39;APl&#39;: nan, &#39;AP-_background_&#39;: nan, &#39;AP-nose&#39;: 37.46745432692759, &#39;AP-left_ear&#39;: 34.99076354765347, &#39;AP-right_ear&#39;: 26.474155569306223, &#39;AP-tail_base&#39;: 40.29951299145698, &#39;AP-mouse&#39;: 75.17536205034328, &#39;AP-centroid&#39;: nan}), (&#39;segm&#39;, {&#39;AP&#39;: 13.838099650346003, &#39;AP50&#39;: 20.663994970925664, &#39;AP75&#39;: 18.99009900990099, &#39;APs&#39;: 0.082999371365708, &#39;APm&#39;: 68.85850076626717, &#39;APl&#39;: nan, &#39;AP-_background_&#39;: nan, &#39;AP-nose&#39;: 0.0, &#39;AP-left_ear&#39;: 0.0, &#39;AP-right_ear&#39;: 0.024752475247524754, &#39;AP-tail_base&#39;: 0.3072450102153072, &#39;AP-mouse&#39;: 68.85850076626717, &#39;AP-centroid&#39;: nan})])
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Annolid_on_Detectron2_Tutorial_2_Train_a_Model.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Annolid on Detectron2 Tutorial 2 : Train a Model</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Annolid_on_Detectron2_Tutorial_4_Running_inference.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Annolid on Detectron2 Tutorial 4 : Running inference</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Chen Yang, Jeremy Forest, Matthew Einhorn, Thomas Cleland<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>