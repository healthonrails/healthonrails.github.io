{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KC_Xi_KM1QJr"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/healthonrails/annolid/blob/main/docs/tutorials/Train_networks_tutorial_v1.0.1.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWzKi-xiGX-i"
   },
   "source": [
    "# Annolid (A segmenation based on mutiple animal tracking package) \n",
    "\n",
    "\n",
    "In this tutorial, we will show how to track multiple animals by detection and instance segmentation. The instance segmenatation on images and video is based on [YOLACT](https://github.com/dbolya/yolact).\n",
    "\n",
    "## Runtime environment in Google Colab\n",
    "Colab is google's free version of Jupyter notebook. \n",
    "This notebook is only tested inside Colab. It might not run in your workstation esp if you are running Windows system. \n",
    "\n",
    "### How to use the free GPU?\n",
    "- Click  **Runtime** > **Change Runtime Type**\n",
    "- Choose **GPU** > **Save**\n",
    "\n",
    "## YOLACT(You Only Look At CoefficienTs)\n",
    "A simple, fully convolutional model for real-time instance segmentation. This is the code for their papers:  \n",
    "- [YOLACT: Real-time Instance Segmentation](https://arxiv.org/abs/1904.02689)\n",
    "- [YOLACT++: Better Real-time Instance Segmentation](https://arxiv.org/abs/1912.06218)\n",
    "\n",
    "## Reference\n",
    "```\n",
    "@inproceedings{yolact-iccv2019,\n",
    "  author    = {Daniel Bolya and Chong Zhou and Fanyi Xiao and Yong Jae Lee},\n",
    "  title     = {YOLACT: {Real-time} Instance Segmentation},\n",
    "  booktitle = {ICCV},\n",
    "  year      = {2019},\n",
    "}\n",
    "```\n",
    "```\n",
    "@misc{yolact-plus-arxiv2019,\n",
    "  title         = {YOLACT++: Better Real-time Instance Segmentation},\n",
    "  author        = {Daniel Bolya and Chong Zhou and Fanyi Xiao and Yong Jae Lee},\n",
    "  year          = {2019},\n",
    "  eprint        = {1912.06218},\n",
    "  archivePrefix = {arXiv},\n",
    "  primaryClass  = {cs.CV}\n",
    "}\n",
    "```\n",
    "This notebook was inspired and modified from https://colab.research.google.com/drive/1ncRxvmNR-iTtQCscj2UFSGV8ZQX_LN0M. \n",
    "https://www.immersivelimit.com/tutorials/yolact-with-google-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPSX2B9oImsQ"
   },
   "source": [
    "# Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cU0BZLJHGSwn"
   },
   "outputs": [],
   "source": [
    "# Cython needs to be installed before pycocotools\n",
    "!pip install cython\n",
    "!pip install opencv-python pillow pycocotools matplotlib \n",
    "!pip install -U PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CT8fVcgZGcoo"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EorT6buddx4X"
   },
   "outputs": [],
   "source": [
    "# DCNv2 will not work if Pytorch is greater than 1.4.0\n",
    "!pip install torchvision==0.5.0\n",
    "!pip install torch==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4EMaf9wI-_M"
   },
   "source": [
    "## Clone and install Annolid from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jpmc_BiNI98H"
   },
   "outputs": [],
   "source": [
    "# The root folder\n",
    "%cd /content\n",
    "# Clone the repo\n",
    "!git clone --recurse-submodules https://github.com/healthonrails/annolid.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "15BkCZALzkLt"
   },
   "outputs": [],
   "source": [
    "# install annolid\n",
    "%cd /content/annolid/\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please uncomment the following cell and update opencv-python in Colab for the errors as follows.\n",
    "File \"eval.py\", line 804, in cleanup_and_exit cv2.destroyAllWindows() cv2.error: OpenCV(4.1.2) /io/opencv/modules/highgui/src/window.cpp:645: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbb_tE0EJNFj"
   },
   "source": [
    "## DCNv2\n",
    "If you want to use YOLACT++, compile deformable convolutional layers (from DCNv2).\n",
    "\n",
    "Note: Make sure you have selected GPU option as discribed in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7XrENaqJU1C"
   },
   "outputs": [],
   "source": [
    "# Change to the DCNv2 directory\n",
    "%cd /content/annolid/annolid/segmentation/yolact/external/DCNv2\n",
    "\n",
    "# Build DCNv2\n",
    "!python setup.py build develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BryENed-JXF8"
   },
   "source": [
    "## Download Pretrained Weights\n",
    "We need to download pre-trained weights for inference. The creator of the GitHub repo shared them on Google Drive. We're going to use a **gdown** to easily access the Drive file from Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "683HeW9lJ6cA"
   },
   "outputs": [],
   "source": [
    "# Make sure we're in the yolact folder\n",
    "%cd /content/annolid/annolid/segmentation/\n",
    "\n",
    "# Create a new directory for the pre-trained weights\n",
    "!mkdir -p /content/annolid/annolid/segmentation/yolact/weights\n",
    "\n",
    "# Download the file\n",
    "!gdown --id 1ZPu1YR2UzGHQD0o1rEqy-j5bmEm3lbyP -O ./yolact/weights/yolact_plus_resnet50_54_800000.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBcnVCw-Ek51"
   },
   "source": [
    "## Train a model\n",
    "You can let the model traing for a few hours. Click the stop by for the cell will interrupt the training and save a interrupted model. \n",
    "Then you can eval the model based with a save model in the yolact/weigths folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VApUPP1dRXXi"
   },
   "outputs": [],
   "source": [
    "# Check the GPU availbe for your run\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tX-58C0iI-KK"
   },
   "source": [
    "## Download an example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdaWF70gjCig"
   },
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/1_kkJ8rlnoMymj0uw8VZkVEuFIMfLDwPh/view?usp=sharing\n",
    "!gdown --id 1_kkJ8rlnoMymj0uw8VZkVEuFIMfLDwPh -O /content/novelctrl_coco_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_scew5KJNlua"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "#rm -rf /content/novelctrl_coco_dataset//\n",
    "#rm -rf /content/annolid/annolid/datasets/novelctrl_coco_dataset\n",
    "unzip /content/novelctrl_coco_dataset.zip -d /content/novelctrl_coco_dataset/\n",
    "# the following command is only for the demo dataset with relative \n",
    "# paths to the dataset in the dataset data.yaml file.\n",
    "mv /content/novelctrl_coco_dataset/novelctrl_coco_dataset/ /content/annolid/annolid/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kod86-p5xMzh"
   },
   "source": [
    "\n",
    "Note please change the path highlighted with ** ** as in the e.g. config data.yaml file to your dataset's location. \n",
    "```bash\n",
    "DATASET:\n",
    "    name: 'novelctrl'\n",
    "    train_info: '**/Users/xxxxxx/xxxxxx/novelctrl_coco_dataset/***train/annotations.json'\n",
    "    train_images: '**/Users/xxxxxx/xxxxxx/novelctrl_coco_dataset/**train'\n",
    "    valid_info: '**/Users/xxxxxx/xxxxxx/novelctrl_coco_dataset/**valid/annotations.json'\n",
    "    valid_images: '**/Users/xxxxxx/xxxxxx/novelctrl_coco_dataset/**valid'\n",
    "    class_names: ['nose', 'left_ear', 'right_ear', 'centroid', 'tail_base', 'tail_end', 'grooming', 'rearing', 'object_investigation', 'left_lateral', 'right_lateral', 'wall_1', 'wall_2', 'wall_3', 'wall_4', 'object_1', 'object_2', 'object_3', 'object_4', 'object_5', 'object_6', 'mouse']\n",
    "YOLACT:\n",
    "    name: 'novelctrl'\n",
    "    dataset: 'dataset_novelctrl_coco'\n",
    "    max_size: 512\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ymzTEBvJHx_"
   },
   "source": [
    "## Start Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wm6TFJd0mXFj"
   },
   "outputs": [],
   "source": [
    "# Start tensorboard for visualization of training\n",
    "%cd /content/annolid/annolid/segmentation/yolact/\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/annolid/runs/logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPSlkwmfOYG-"
   },
   "outputs": [],
   "source": [
    "%cd /content/annolid/annolid/segmentation/yolact/\n",
    "!python train.py --config=../../datasets/novelctrl_coco_dataset/data.yaml --batch_size=16 --keep_latest_interval=100 # --resume=weights/novelctrl_244_2202_interrupt.pth --start_iter=244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWFtsnMDJbNT"
   },
   "source": [
    "## Mount your GOOGLE Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCHbVxdhJvlC"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCTIeYtwJ3To"
   },
   "source": [
    "## Save a trained model to your Google Drive\n",
    "Please replace and put your_model_xxx.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEAN7NShoqOg"
   },
   "outputs": [],
   "source": [
    "# e.g. \n",
    "!cp /content/annolid/annolid/segmentation/yolact/weights/your_model_xxxx.pth /content/drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcIk0UG38Z1P"
   },
   "outputs": [],
   "source": [
    "# optional\n",
    "#!cp /content/annolid/annolid/segmentation/yolact/weights/resnet50-19c8e357.pth /content/drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqmzeZNLKfjr"
   },
   "source": [
    "## Download the original video and test it based on your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrN1oegixBF6"
   },
   "outputs": [],
   "source": [
    "# https://drive.google.com/file/d/1_UDnyYKQplOLMzv1hphk1gVqepmLeyGD/view?usp=sharing\n",
    "!gdown --id 1_UDnyYKQplOLMzv1hphk1gVqepmLeyGD -O /content/novelctrl.mkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfbcPhD13Tqt"
   },
   "outputs": [],
   "source": [
    "!python eval.py --trained_model=weights/novelctrl_xxxx_xxxx.pth --config=../../datasets/novelctrl_coco/data.yaml --score_threshold=0.15 --top_k=9 --video_multiframe=1 --video=/content/novelctrl.mkv:novelctrl_tracked.mkv --display_mask=False --mot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5h06K5kPwo2y"
   },
   "source": [
    "The output results are located at /content/annolid/annolid/segmentation/yolact/results.\n",
    "\n",
    "tracking_results.csv\n",
    "\n",
    "xxxx_video_tracked.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gO4I5WrdwyXA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train networks tutorial v1.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}